{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "경진대회.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1UhTrXt985t5ptIAIelNIEMBoOoat6WYz",
      "authorship_tag": "ABX9TyNrFt8inFdbRu0Ppm/ixwpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkckdals3/ML_/blob/main/%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IruI6Dc5AYew"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnRN6jh-Blif",
        "outputId": "31a51802-1452-4f9c-f6ac-0e3b377c8aef"
      },
      "source": [
        "import glob\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "#train 타겟값 target에 저장\n",
        "target_table=pd.read_csv('/gdrive/MyDrive/SyntekaBio/train_output.csv').to_numpy()\n",
        "target=target_table[:,1:].astype(float)\n",
        "train_data =(sorted(glob.glob('/gdrive/MyDrive/SyntekaBio/train/PNG/*.png')))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9DFtkxZB5cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46f2703-78be-40f1-fadc-68749528fb1b"
      },
      "source": [
        "#전체 데이터 불러오기/데이터 10분에 1로 축소\n",
        "for i in range (len(train_data)):\n",
        "  train_data[i]=cv2.imread(train_data[i])\n",
        "  train_data[i]=cv2.resize(train_data[i],dsize=(128, 128),interpolation=cv2.INTER_AREA)\n",
        "  train_data[i]=train_data[i].astype(np.float32)/255\n",
        "train_scaled=np.array(train_data)\n",
        "train_scaled.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(501, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dDSYMJpDant",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd310f9-1867-4e02-8679-f53a4ff49230"
      },
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled.reshape(-1,128,128,3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 0.        , 0.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.7254902 , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.7254902 , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.7254902 , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.7254902 , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 0.        , 0.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 0.        , 0.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[0.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [0.        , 0.        , 1.        ],\n",
              "         [1.        , 1.        , 0.84313726]],\n",
              "\n",
              "        [[1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         ...,\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726],\n",
              "         [1.        , 1.        , 0.84313726]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clgdOjT-_v0T",
        "outputId": "45fff188-d085-43c6-ebba-416e398e921a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled,val_scaled,train_target,val_target=train_test_split(train_scaled,target,test_size=0.2)\n",
        "print('학습 데이터 shape : ', train_scaled.shape)\n",
        "print('검증 데이터 shape : ', val_scaled.shape)\n",
        "print('학습 타겟 shape : ', train_target.shape)\n",
        "print('검증 타겟 shape : ', val_target.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 shape :  (400, 128, 128, 3)\n",
            "검증 데이터 shape :  (101, 128, 128, 3)\n",
            "학습 타겟 shape :  (400, 1)\n",
            "검증 타겟 shape :  (101, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISkDoGuPM1iO"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "model.add(keras.layers.BatchNormalization(center=True, scale=True))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "model.add(keras.layers.BatchNormalization(center=True, scale=True))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(1, activation='softmax'))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha08LuZINC7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1840aa5b-4185-4f2d-a149-ac6bcbfa4ee7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 63, 63, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 30, 30, 64)        256       \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               5760100   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 5,779,977\n",
            "Trainable params: 5,779,785\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qrpevfsfv1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966041fc-8d89-4bdd-fee7-39b88ac94a1b"
      },
      "source": [
        "import tensorflow\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "print(train_scaled.shape)\n",
        "print(train_target.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 128, 128, 3)\n",
            "(400, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H0dVBkYQNGIu",
        "outputId": "37fc1021-43cd-43f4-efea-dc54c6c09d5e"
      },
      "source": [
        "history = model.fit(\n",
        "            train_scaled, train_target, \n",
        "            validation_data = (val_scaled,val_target),\n",
        "            verbose = 1,\n",
        "            batch_size = 32,\n",
        "            epochs = 30\n",
        "                    )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 5s 410ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 5s 398ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 5s 384ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 5s 390ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 5s 390ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 5s 390ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 5s 389ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 5s 396ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 5s 397ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 5s 395ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 5s 384ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 5s 387ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 5s 390ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 5s 395ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 5s 393ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 5s 393ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 5s 389ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 5s 396ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 5s 390ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 5s 394ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 5s 391ms/step - loss: 0.0000e+00 - accuracy: 0.6600 - val_loss: 0.0000e+00 - val_accuracy: 0.6733\n",
            "Epoch 22/30\n",
            " 1/12 [=>............................] - ETA: 4s - loss: 0.0000e+00 - accuracy: 0.7059"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-255c3b57420a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQqTuSSzV350"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}